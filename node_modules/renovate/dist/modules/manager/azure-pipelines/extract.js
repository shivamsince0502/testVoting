"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.extractPackageFile = exports.parseAzurePipelines = exports.extractAzurePipelinesTasks = exports.extractContainer = exports.extractRepository = void 0;
const js_yaml_1 = require("js-yaml");
const global_1 = require("../../../config/global");
const logger_1 = require("../../../logger");
const array_1 = require("../../../util/array");
const regex_1 = require("../../../util/regex");
const url_1 = require("../../../util/url");
const azure_pipelines_tasks_1 = require("../../datasource/azure-pipelines-tasks");
const git_tags_1 = require("../../datasource/git-tags");
const extract_1 = require("../dockerfile/extract");
const AzurePipelinesTaskRegex = (0, regex_1.regEx)(/^(?<name>[^@]+)@(?<version>.*)$/);
function extractRepository(repository) {
    let repositoryUrl = null;
    if (repository.type === 'github') {
        repositoryUrl = `https://github.com/${repository.name}.git`;
    }
    else if (repository.type === 'git') {
        // "git" type indicates an AzureDevOps repository.
        // The repository URL is only deducible if we are running on AzureDevOps (so can use the endpoint)
        // and the name is of the form `Project/Repository`.
        // The name could just be the repository name, in which case AzureDevOps defaults to the
        // same project, which is not currently accessible here. It could be deduced later by exposing
        // the repository URL to managers.
        // https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema/resources-repositories-repository?view=azure-pipelines#types
        const platform = global_1.GlobalConfig.get('platform');
        const endpoint = global_1.GlobalConfig.get('endpoint');
        if (platform === 'azure' && endpoint) {
            if (repository.name.includes('/')) {
                const [projectName, repoName] = repository.name.split('/');
                repositoryUrl = (0, url_1.joinUrlParts)(endpoint, encodeURIComponent(projectName), '_git', encodeURIComponent(repoName));
            }
            else {
                logger_1.logger.debug('Renovate cannot update repositories that do not include the project name');
            }
        }
    }
    if (repositoryUrl === null) {
        return null;
    }
    if (!repository.ref?.startsWith('refs/tags/')) {
        return null;
    }
    return {
        autoReplaceStringTemplate: 'refs/tags/{{newValue}}',
        currentValue: repository.ref.replace('refs/tags/', ''),
        datasource: git_tags_1.GitTagsDatasource.id,
        depName: repository.name,
        depType: 'gitTags',
        packageName: repositoryUrl,
        replaceString: repository.ref,
    };
}
exports.extractRepository = extractRepository;
function extractContainer(container) {
    if (!container.image) {
        return null;
    }
    const dep = (0, extract_1.getDep)(container.image);
    logger_1.logger.debug({
        depName: dep.depName,
        currentValue: dep.currentValue,
        currentDigest: dep.currentDigest,
    }, 'Azure pipelines docker image');
    dep.depType = 'docker';
    return dep;
}
exports.extractContainer = extractContainer;
function extractAzurePipelinesTasks(task) {
    const match = AzurePipelinesTaskRegex.exec(task);
    if (match?.groups) {
        return {
            depName: match.groups.name,
            currentValue: match.groups.version,
            datasource: azure_pipelines_tasks_1.AzurePipelinesTasksDatasource.id,
        };
    }
    return null;
}
exports.extractAzurePipelinesTasks = extractAzurePipelinesTasks;
function parseAzurePipelines(content, packageFile) {
    let pkg = null;
    try {
        pkg = (0, js_yaml_1.load)(content, { json: true });
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.debug({ packageFile, err }, 'Error parsing azure-pipelines content');
        return null;
    }
    return pkg;
}
exports.parseAzurePipelines = parseAzurePipelines;
function extractPackageFile(content, packageFile) {
    logger_1.logger.trace(`azurePipelines.extractPackageFile(${packageFile})`);
    const deps = [];
    const pkg = parseAzurePipelines(content, packageFile);
    if (!pkg) {
        return null;
    }
    for (const repository of (0, array_1.coerceArray)(pkg.resources?.repositories)) {
        const dep = extractRepository(repository);
        if (dep) {
            deps.push(dep);
        }
    }
    for (const container of (0, array_1.coerceArray)(pkg.resources?.containers)) {
        const dep = extractContainer(container);
        if (dep) {
            deps.push(dep);
        }
    }
    for (const { jobs } of (0, array_1.coerceArray)(pkg.stages)) {
        for (const { steps } of (0, array_1.coerceArray)(jobs)) {
            for (const step of (0, array_1.coerceArray)(steps)) {
                const task = extractAzurePipelinesTasks(step.task);
                if (task) {
                    deps.push(task);
                }
            }
        }
    }
    for (const { steps } of (0, array_1.coerceArray)(pkg.jobs)) {
        for (const step of (0, array_1.coerceArray)(steps)) {
            const task = extractAzurePipelinesTasks(step.task);
            if (task) {
                deps.push(task);
            }
        }
    }
    for (const step of (0, array_1.coerceArray)(pkg.steps)) {
        const task = extractAzurePipelinesTasks(step.task);
        if (task) {
            deps.push(task);
        }
    }
    if (!deps.length) {
        return null;
    }
    return { deps };
}
exports.extractPackageFile = extractPackageFile;
//# sourceMappingURL=extract.js.map